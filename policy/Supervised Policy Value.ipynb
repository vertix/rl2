{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import zmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_socket_addr = \"tcp://127.0.0.1:29884\"\n",
    "max_actions = 7\n",
    "strat_socket_addr = \"tcp://127.0.0.1:29885\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "sock_exp = context.socket(zmq.REP)\n",
    "sock_exp.bind(exp_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sock_strat = context.socket(zmq.PUB)\n",
    "sock_strat.bind(strat_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CreateNetworks(state, num_actions, is_training=True, reuse=False):\n",
    "    with tf.variable_scope('common'):\n",
    "        hidden1 = tf.contrib.layers.relu(\n",
    "            state, NUM_HIDDEN,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "            biases_initializer=tf.constant_initializer(0.01),\n",
    "#             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "#             normalizer_params={'is_training': is_training},\n",
    "            scope='hidden1',\n",
    "            reuse=reuse)\n",
    "        hidden2 = tf.contrib.layers.relu(\n",
    "            hidden1, NUM_HIDDEN,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "            biases_initializer=tf.constant_initializer(0.01),\n",
    "#             normalizer_fn=tf.contrib.layers.batch_norm,\n",
    "#             normalizer_params={'is_training': is_training},\n",
    "            scope='hidden2',\n",
    "            reuse=reuse)\n",
    "    \n",
    "    with tf.variable_scope('value'):\n",
    "        value = tf.contrib.layers.linear(hidden2, 1,\n",
    "                                         weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                         scope='value',\n",
    "                                         reuse=reuse)\n",
    "        value = tf.squeeze(value)\n",
    "#         return value\n",
    "    if not reuse:\n",
    "        with tf.variable_scope('policy'):\n",
    "            logits = tf.contrib.layers.linear(hidden2, num_actions,\n",
    "                                              weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                              scope='policy',\n",
    "                                              reuse=reuse)\n",
    "    else:\n",
    "        logits = None\n",
    "    return logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_OPTIONS = {\n",
    "    'clip_grad': 3.,\n",
    "    'learning_rate': 0.0001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HuberLoss(tensor, boundary):\n",
    "    abs_x = tf.abs(tensor)\n",
    "    delta = boundary\n",
    "    quad = tf.minimum(abs_x, delta)\n",
    "    lin = (abs_x - quad)\n",
    "    return 0.5 * quad**2 + delta * lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ActorCritic(object):\n",
    "    def __init__(self, build_networks, buf, options=DEFAULT_OPTIONS):\n",
    "        self._options = options\n",
    "        self.exp_buffer = buf\n",
    "        with tf.device('/cpu:0'):\n",
    "            self.state = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state')\n",
    "            self.action = tf.placeholder(tf.int32, shape=[None], name='action')\n",
    "            self.reward = tf.placeholder(tf.float32, shape=[None], name='reward')\n",
    "            self.state1 = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state1')\n",
    "            self.gamma = tf.placeholder(tf.float32, shape=[None], name='gamma')\n",
    "            self.is_weights = tf.placeholder(tf.float32, shape=[None], name='is_weights')       \n",
    "            self.is_training = tf.placeholder(tf.bool, shape=None, name='is_training')\n",
    "\n",
    "            self.logits, self.baseline = build_networks(self.state,\n",
    "                                                        is_training=self.is_training, reuse=False)\n",
    "            _,  self.baseline1 = build_networks(self.state1, is_training=False, reuse=True)\n",
    "            self.tf_policy = tf.reshape(tf.multinomial(self.logits, 1), [])\n",
    "\n",
    "            # Experimental\n",
    "            self.rolled_baseline = tf.stop_gradient(self.reward + self.gamma * self.baseline1)\n",
    "            self.advantage = self.rolled_baseline - self.baseline\n",
    "            \n",
    "            self.cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(self.logits, self.action)\n",
    "            self.policy_loss = tf.reduce_mean(self.cross_entropy)\n",
    "            # For actor-critic this should look like:\n",
    "            # self.policy_loss = tf.reduce_mean(\n",
    "            #     tf.mul(self.cross_entropy, tf.stop_gradient(self.advantage)))\n",
    "            \n",
    "            self.value_loss = 0.5 * tf.reduce_mean(HuberLoss(self.advantage, 5))\n",
    "\n",
    "            self.policy_entropy = tf.reduce_mean(-tf.nn.softmax(self.logits) * \n",
    "                                                 tf.nn.log_softmax(self.logits))\n",
    "\n",
    "#             loss = self.value_loss\n",
    "            loss = self.policy_loss + 0.25 * self.value_loss - 0.01 * self.policy_entropy\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(options['learning_rate'])\n",
    "            grads = self.optimizer.compute_gradients(loss, tf.get_collection(tf.GraphKeys.VARIABLES))\n",
    "            if 'clip_grad' in options:\n",
    "                grads = [(tf.clip_by_norm(g, options['clip_grad']) if g is not None else None, v)\n",
    "                         for g, v in grads]\n",
    "\n",
    "            for grad, var in grads:\n",
    "                tf.histogram_summary(var.name, var)\n",
    "                if grad is not None:\n",
    "                    tf.histogram_summary('{}/grad'.format(var.name), grad)            \n",
    "\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            self.train_op = self.optimizer.apply_gradients(grads, self.global_step)\n",
    "            \n",
    "            tf.histogram_summary(\"Predicted baseline\", self.baseline)\n",
    "            tf.histogram_summary(\"TD error\", self.advantage)\n",
    "            tf.scalar_summary(\"Loss/Actor\", self.policy_loss)\n",
    "            tf.scalar_summary(\"Loss/Critic\", self.value_loss)\n",
    "            tf.scalar_summary(\"Loss/Entropy\", self.policy_entropy)\n",
    "            tf.scalar_summary(\"Loss/Total\", loss)\n",
    "\n",
    "            self.summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    def Init(self, sess, run_id):\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        self.writer = tf.train.SummaryWriter(\n",
    "            '/Users/vertix/tf/tensorflow_logs/aicup/%s'  % run_id\n",
    "#             '/media/vertix/UHDD/tmp/tensorflow_logs/aicup/%s' % run_id\n",
    "        )\n",
    "        self.saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.VARIABLES))\n",
    "        self.last_start = time.time()\n",
    "        self.cur_step = 0\n",
    "        self.writer.add_graph(tf.get_default_graph())\n",
    "\n",
    "    def Step(self, sess, batch_size=32):\n",
    "        idx, ss, aa, rr, ss1, gg, ww = self.exp_buffer.sample(batch_size)\n",
    "        if ss is None:\n",
    "            return\n",
    "        \n",
    "        feed_dict = {self.state: ss, self.action: aa, self.reward: rr, self.state1:ss1,\n",
    "                     self.gamma: gg, self.is_weights: ww,\n",
    "                     self.is_training: True}\n",
    "\n",
    "        if self.cur_step and self.cur_step % 100 != 0:\n",
    "            self.cur_step, _ = sess.run(\n",
    "                [self.global_step, self.train_op], feed_dict)\n",
    "        else:\n",
    "            self.cur_step, _, smr = sess.run(\n",
    "                [self.global_step, self.train_op, self.summary_op], feed_dict)\n",
    "            self.writer.add_summary(smr, self.cur_step)\n",
    "                    \n",
    "        if self.cur_step % 20000 == 0:\n",
    "            self.saver.save(sess, 'ac', global_step=self.global_step)\n",
    "            if self.last_start is not None:\n",
    "                self.writer.add_summary(\n",
    "                    tf.Summary(\n",
    "                        value=[tf.Summary.Value(\n",
    "                                tag='Steps per sec',\n",
    "                                simple_value=20000 / (time.time() - self.last_start))]),\n",
    "                    self.cur_step)\n",
    "            self.last_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = WeightedExperienceBuffer(0.0, 0.0, 100, buffer_size=1<<16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e4f7660d918f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_pyobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msock_exp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vertix/anaconda/lib/python2.7/site-packages/zmq/sugar/socket.pyc\u001b[0m in \u001b[0;36mrecv_pyobj\u001b[0;34m(self, flags)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0marrives\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:6971)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:6763)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:1931)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/vertix/tf/lib/python2.7/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:7222)\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \"\"\"\n\u001b[1;32m     11\u001b[0m     \u001b[0mcdef\u001b[0m \u001b[0mint\u001b[0m \u001b[0merrno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzmq_errno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mPyErr_CheckSignals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if rc < -1, it's a bug in libzmq. Should we warn?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(120000):\n",
    "    msg = sock_exp.recv_pyobj()\n",
    "    sock_exp.send('Ok')\n",
    "    if msg['type'] == 'exp':\n",
    "        msg = msg['data']\n",
    "        buf.add(msg['s'], msg['a'], msg['r'], msg['s1'], msg['g'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291370"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf.inserted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ac = ActorCritic(lambda x, **kwargs: CreateNetworks(x, 7, **kwargs), buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac.Init(sess, 'ac5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ac.saver.restore(sess, 'ac-1600000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(15 * 10 ** 6):\n",
    "    ac.Step(sess)\n",
    "    if i % 15 == 0:\n",
    "        msg = sock_exp.recv_pyobj()\n",
    "        sock_exp.send('Ok')\n",
    "\n",
    "        if msg['type'] == 'exp':\n",
    "            msg = msg['data']\n",
    "            ac.exp_buffer.add(msg['s'], msg['a'], msg['r'], msg['s1'], msg['g'], 100)\n",
    "        elif msg['type'] == 'stat':\n",
    "            pass\n",
    "    \n",
    "    if i % 20000 == 19999:\n",
    "        DumpVariables('network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270804"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.exp_buffer.inserted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ac.exp_buffer.alpha = 0.0 # 0.6\n",
    "ac.exp_buffer.beta = 0.0  # 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_, s, a, r, s1, g, _ = ac.exp_buffer.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  0.,\n",
       "        0.,  0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    82.,    100.,     94., ...,      0.,      0.,  17109.],\n",
       "       [    85.,    100.,    100., ...,      0.,      0.,  16189.],\n",
       "       [    99.,    100.,    100., ...,      0.,      0.,  11901.],\n",
       "       ..., \n",
       "       [    98.,    100.,     99., ...,      0.,      0.,  14029.],\n",
       "       [    85.,    100.,     97., ...,      0.,      0.,  12189.],\n",
       "       [    88.,    100.,     99., ...,      0.,      0.,   4460.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04569197,  0.0302515 , -0.13130021,  0.00646222, -0.08189249,\n",
       "        0.01194906,  0.02656126, -0.10169649,  0.02854085, -0.10737276,\n",
       "        0.02418947, -2.79416704, -0.14544439, -0.07501316,  0.0362587 ], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ac.td_error, {ac.state: s, ac.state1: s1,  ac.reward: r, ac.gamma: g,\n",
    "                       ac.is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.08676052,  4.56864262,  2.74127364,  1.40395606,  4.47205591,\n",
       "        3.96832752,  4.63735485,  4.69036865,  3.74232721,  4.2821207 ,\n",
       "        4.1466217 ,  5.06364107,  2.63035035,  4.02202797,  4.52581549], dtype=float32)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ac.baseline, {ac.state: s, ac.state1: s1,  ac.reward: r, ac.gamma: g,\n",
    "                       ac.is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.06640053,  4.56119728,  2.88700891,  1.40451646,  4.57683277,\n",
       "        3.97625971,  4.63396358,  4.8161459 ,  3.73244858,  4.411551  ,\n",
       "        4.14314795,  4.88221931,  2.78974342,  4.11762905,  4.51211739], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ac.baseline1, {ac.state: s, ac.state1: s1,  ac.reward: r, ac.gamma: g,\n",
    "                       ac.is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common/hidden1/weights:0\n",
      "common/hidden1/biases:0\n",
      "common/hidden2/weights:0\n",
      "common/hidden2/biases:0\n",
      "value/value/weights:0\n",
      "value/value/biases:0\n",
      "policy/policy/weights:0\n",
      "policy/policy/biases:0\n",
      "global_step:0\n",
      "beta1_power:0\n",
      "beta2_power:0\n",
      "common/hidden1/weights/Adam:0\n",
      "common/hidden1/weights/Adam_1:0\n",
      "common/hidden1/biases/Adam:0\n",
      "common/hidden1/biases/Adam_1:0\n",
      "common/hidden2/weights/Adam:0\n",
      "common/hidden2/weights/Adam_1:0\n",
      "common/hidden2/biases/Adam:0\n",
      "common/hidden2/biases/Adam_1:0\n",
      "value/value/weights/Adam:0\n",
      "value/value/weights/Adam_1:0\n",
      "value/value/biases/Adam:0\n",
      "value/value/biases/Adam_1:0\n",
      "policy/policy/weights/Adam:0\n",
      "policy/policy/weights/Adam_1:0\n",
      "policy/policy/biases/Adam:0\n",
      "policy/policy/biases/Adam_1:0\n"
     ]
    }
   ],
   "source": [
    "for v in tf.get_collection(tf.GraphKeys.VARIABLES):\n",
    "    print v.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "def DumpVariables(filename):\n",
    "    network_vars = {}\n",
    "    for v in tf.get_collection(tf.GraphKeys.VARIABLES):\n",
    "        if '/' in v.name and 'Adam' not in v.name:\n",
    "            network_vars[v.name] = v.eval()\n",
    "    with open(filename, 'w') as f:\n",
    "        cPickle.dump(network_vars, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DumpVariables('network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BatchNorm(state, network_vars, key):\n",
    "    eps = 0.001\n",
    "    inv = 1.0 / np.sqrt(network_vars[key + '/moving_variance:0'] + eps)\n",
    "\n",
    "    return state * inv + (network_vars[key + '/beta:0'] - network_vars[key + '/moving_mean:0'] * inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Softmax(state):\n",
    "    state -= np.max(state)\n",
    "    e = np.exp(state)\n",
    "    return e / np.sum(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NNPolicy(object):\n",
    "    def __init__(self, network_vars):\n",
    "        self.vars = network_vars\n",
    "        self.actions = None\n",
    "\n",
    "    def Logits(self, state):\n",
    "        state = np.matmul(state, self.vars['common/hidden1/weights:0'])\n",
    "        state += self.vars['common/hidden1/biases:0']\n",
    "        state = ReLu(state)\n",
    "\n",
    "        state = np.matmul(state, self.vars['common/hidden2/weights:0'])\n",
    "        state += self.vars['common/hidden2/biases:0']\n",
    "        state = ReLu(state)\n",
    "\n",
    "        logits = np.matmul(state, self.vars['policy/policy/weights:0'])\n",
    "        logits += self.vars['policy/policy/biases:0']\n",
    "        return logits\n",
    "    \n",
    "    def Softmax(self, state):\n",
    "        logits = self.Logits(state)\n",
    "        return Softmax(logits)\n",
    "    \n",
    "    def Sample(self, state):\n",
    "        sm = self.Softmax(state)\n",
    "        if self.actions is None:\n",
    "            self.actions = range(len(sm))\n",
    "        return np.random.choice(self.actions, p=sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnp = NNPolicy(network_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.60286788e-05,   1.27642462e-75,   1.33276611e-08,\n",
       "         5.64379590e-10,   8.89499400e-01,   1.10444557e-01,\n",
       "         1.42909448e-18])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnp.Softmax(s[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnp.Sample(s[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00021755436517878479"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(nnp.Logits(s) -  ac.logits.eval({ac.state: s}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 7)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.logits.eval({ac.state: s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4263148 ,  0.27988333,  0.52581638,  0.42325473,  0.46426272,\n",
       "         0.47350475,  0.352005  ]], dtype=float32)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.pred_vars[6].eval({ql.state: ss, ql.is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.42631482,  0.27988335,  0.52581639,  0.4232547 ,  0.46426274,\n",
       "         0.47350477,  0.352005  ]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QFunction(network_vars).Q(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1746.92163086,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,  3156.87939453], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(ql.copy_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Select(ql.pred_vars[2], ql.action).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(ql.pred_vars[2] * tf.one_hot(ql.action, ql.num_actions), reduction_indices=1).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7], dtype=int32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(ql.pred_vars[2]).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.delta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(ql.delta).eval({ql.state: ss, ql.action: aa, ql.reward: rr, ql.state1:ss1, ql.gamma: gg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,  2561.84985352,  2696.66064453,\n",
       "        3319.86474609,  2376.26171875,  2375.80859375,  2602.42016602,\n",
       "        2548.83056641,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval({ql.state: ss, ql.action: aa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268,\n",
       "        9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval({ql.state1: ss1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
