{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import zmq\n",
    "\n",
    "from tensorflow.python.training import moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'learner' from 'learner.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import learner\n",
    "reload(learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_socket_addr = \"tcp://127.0.0.1:19884\" \n",
    "max_actions = 7\n",
    "strat_socket_addr = \"tcp://127.0.0.1:19885\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "sock_exp = context.socket(zmq.REP)\n",
    "sock_exp.bind(exp_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sock_strat = context.socket(zmq.PUB)\n",
    "sock_strat.bind(strat_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_HIDDEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CreateNetwork(state, num_actions, scope, is_training, reuse=False):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "#         moving_mean = tf.get_variable('mean', shape=state.get_shape()[1],\n",
    "#                             initializer=tf.zeros_initializer,\n",
    "#                             trainable=False)\n",
    "#         moving_var = tf.get_variable('var', shape=state.get_shape()[1],\n",
    "#                             initializer=tf.ones_initializer, \n",
    "#                             trainable=False)\n",
    "#         state = (state - moving_mean) / tf.sqrt(moving_var + 0.001)\n",
    "        \n",
    "        hidden1 = tf.contrib.layers.fully_connected(\n",
    "            state, NUM_HIDDEN,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "#             weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            biases_initializer=tf.constant_initializer(0.01),\n",
    "            scope='hidden1', reuse=reuse)\n",
    "        hidden2 = tf.contrib.layers.relu(\n",
    "            hidden1, NUM_HIDDEN,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "#             weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "            biases_initializer=tf.constant_initializer(0.01),\n",
    "            scope='hidden2', reuse=reuse)\n",
    "\n",
    "    #     value_hid = tf.contrib.layers.relu(hidden2, NUM_HIDDEN,\n",
    "    #         weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "    #         biases_initializer=tf.constant_initializer(0.01),\n",
    "    #         scope=scope + '/val_hid', reuse=reuse)\n",
    "\n",
    "    #     adv_hid = tf.contrib.layers.relu(hidden2, NUM_HIDDEN,\n",
    "    #         weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "    #         biases_initializer=tf.constant_initializer(0.01),\n",
    "    #         scope=scope + '/adv_hid', reuse=reuse)\n",
    "\n",
    "        value = tf.contrib.layers.linear(hidden2, 1,\n",
    "                                         weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "#                                          weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                         biases_initializer=tf.constant_initializer(0.),\n",
    "                                         scope='value')\n",
    "        adv = tf.contrib.layers.linear(hidden2, num_actions,\n",
    "                                       weights_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "#                                        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                       scope='advantage')\n",
    "        adv = tf.sub(adv, tf.reduce_mean(adv, reduction_indices=1, keep_dims=True), 'advantage')\n",
    "\n",
    "        output = tf.add(value, adv, 'output')\n",
    "    #     return hidden1, hidden2, value_hid, adv_hid, value, adv, output\n",
    "#         return moving_mean, moving_var, state, hidden1, hidden2, value, adv, output\n",
    "    return hidden1, hidden2, value, adv, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Select(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    batch_size = tf.shape(value)[0]\n",
    "    _range = tf.range(0, batch_size)\n",
    "    ind = tf.concat(1, [tf.expand_dims(_range, 1), \n",
    "                        tf.expand_dims(index, 1)])\n",
    "    return tf.gather_nd(value, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Select4(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    shp = tf.shape(value)\n",
    "    return tf.reduce_sum(value * tf.one_hot(index, shp[1]), reduction_indices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEFAULT_OPTIONS = {\n",
    "    'clip_grad': 3.,\n",
    "    'learning_rate': 0.001,\n",
    "    'update_steps': 10000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the normalization coefficients for state\n",
    "size = min(buf.inserted, buf.buffer_size)\n",
    "STATE_MEAN, STATE_STD = buf.ss[:, :size].mean(1), buf.ss[:, :size].std(1) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'asdfadsfasdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class QLearner(object):\n",
    "    def __init__(self, exp_buffer, num_actions, run_index, options=DEFAULT_OPTIONS):\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self.num_actions = num_actions\n",
    "        self.run_index = run_index\n",
    "        self.options = options\n",
    "\n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state')\n",
    "        self.action = tf.placeholder(tf.int32, shape=[None], name='action')\n",
    "        self.reward = tf.placeholder(tf.float32, shape=[None], name='reward')\n",
    "        self.state1 = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state1')\n",
    "        self.gamma = tf.placeholder(tf.float32, shape=[None], name='gamma')\n",
    "        self.is_weights = tf.placeholder(tf.float32, shape=[None], name='is_weights')       \n",
    "        self.is_training = tf.placeholder(tf.bool, shape=None, name='is_training')\n",
    "\n",
    "        mean = tf.get_variable('mean', dtype=tf.float32,\n",
    "                               initializer=STATE_MEAN, trainable=False)\n",
    "        std = tf.get_variable('std', dtype=tf.float32,\n",
    "                              initializer=STATE_STD, trainable=False)       \n",
    "        \n",
    "#         norm_state = (self.state - self.moving_mean) / tf.sqrt(self.moving_var + 0.001)\n",
    "#         norm_state1 = (self.state1 - self.moving_mean) / tf.sqrt(self.moving_var + 0.001)\n",
    "        norm_state = (self.state - tf.identity(mean)) / tf.identity(std)\n",
    "        norm_state1 = (self.state1 - mean) / std\n",
    "\n",
    "        self.pred_vars = CreateNetwork(norm_state, num_actions, 'model', self.is_training)\n",
    "        self.pred_vars_s1 = CreateNetwork(norm_state1, num_actions, 'model', self.is_training, True)\n",
    "        self.target_vars = CreateNetwork(norm_state1, num_actions, 'target', False)\n",
    "\n",
    "#         self.mean, self.var = tf.nn.moments(self.state, [0])\n",
    "#         self.mean_update = moving_averages.assign_moving_average(self.pred_vars[0], self.mean, 0.99)\n",
    "#         self.var_update = moving_averages.assign_moving_average(self.pred_vars[1], self.var, 0.99)\n",
    "        \n",
    "        self.vars_pred = tf.get_collection(tf.GraphKeys.VARIABLES, 'model')\n",
    "        self.vars_target = tf.get_collection(tf.GraphKeys.VARIABLES, 'target')\n",
    "        \n",
    "        self.copy_op = tf.group(\n",
    "            *[tf.assign(y, x) for x, y in zip(self.vars_pred, self.vars_target)]\n",
    "        )\n",
    "        self.vars_pred.extend([mean, std])\n",
    "\n",
    "        idx = len(self.pred_vars) - 1\n",
    "\n",
    "        self.act_s1 = tf.cast(tf.argmax(self.pred_vars_s1[idx], dimension=1), tf.int32)\n",
    "        self.q_s1 = Select(self.target_vars[idx], self.act_s1)\n",
    "        self.target_q = tf.stop_gradient(self.reward + self.gamma * self.q_s1)\n",
    "        self.q = Select4(self.pred_vars[idx], self.action)\n",
    "\n",
    "        self.delta = self.target_q - self.q\n",
    "        self.td_err_weight = tf.abs(self.delta)\n",
    "        self.loss = tf.reduce_mean(learner.HuberLoss(self.delta, 5) * self.is_weights)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(options['learning_rate'])\n",
    "        grads = optimizer.compute_gradients(self.loss, tf.get_collection(\n",
    "                tf.GraphKeys.TRAINABLE_VARIABLES, 'model'))\n",
    "        if 'clip_grad' in options:\n",
    "            grads = [(tf.clip_by_norm(g, options['clip_grad']) if g is not None else None, v)\n",
    "                     for g, v in grads]\n",
    "\n",
    "        for grad, v in grads:\n",
    "            if grad is not None:\n",
    "                tf.histogram_summary('{}/grad'.format(v.name), grad)\n",
    "                \n",
    "        for v in tf.get_collection(tf.GraphKeys.VARIABLES):\n",
    "            tf.histogram_summary(v.name, v)\n",
    "\n",
    "#         for v in self.pred_vars[:2]:\n",
    "#             tf.histogram_summary(v.name, v)\n",
    "\n",
    "        for ten in self.pred_vars:\n",
    "            tf.histogram_summary('vars/' + ten.name, ten)\n",
    "\n",
    "        tf.histogram_summary('Monitor/TD Error', self.delta)\n",
    "        tf.histogram_summary('Monitor/Q', self.q)\n",
    "        tf.histogram_summary('Monitor/Weights', self.is_weights)\n",
    "        tf.scalar_summary(\"Scalars/Loss\", self.loss)\n",
    "        tf.scalar_summary(\"Scalars/Q Func\", tf.reduce_mean(self.q))\n",
    "        tf.scalar_summary('Scalars/Weights', tf.reduce_mean(self.is_weights))\n",
    "            \n",
    "        self.train_op = optimizer.apply_gradients(grads, self.global_step)\n",
    "#         if update_ops:\n",
    "        self.train_op = tf.group(#tf.add_check_numerics_ops(), \n",
    "                                 self.train_op, #self.mean_update, self.var_update,\n",
    "                                 *update_ops)\n",
    "\n",
    "        self.summary_op = tf.merge_all_summaries()\n",
    "        self.writer = None\n",
    "        self.saver = None\n",
    "        self.cur_step = None\n",
    "\n",
    "    def step(self, sess, batch_size=32):\n",
    "        idx, ss, aa, rr, ss1, gg, ww = self.exp_buffer.sample(batch_size)\n",
    "        if ss is None:\n",
    "            return\n",
    "        \n",
    "        if self.writer is None:\n",
    "            self.writer = tf.train.SummaryWriter(#'/Users/vertix/tf/tensorflow_logs/aicup/%s'\n",
    "                                                 '/media/vertix/UHDD/tmp/tensorflow_logs/aicup/%s'\n",
    "                                                 % self.run_index)\n",
    "            self.saver = tf.train.Saver(self.vars_pred)\n",
    "            self.last_start = time.time()\n",
    "\n",
    "        feed_dict = {self.state: ss, self.action: aa, self.reward: rr, self.state1:ss1,\n",
    "                     self.gamma: gg, self.is_weights: ww,\n",
    "                     self.is_training: True}\n",
    "\n",
    "        if self.cur_step and self.cur_step % 100 != 0:\n",
    "            self.cur_step, weights, _ = sess.run(\n",
    "                [self.global_step, self.td_err_weight, self.train_op], feed_dict)\n",
    "        else:\n",
    "            self.cur_step, weights, _, smr = sess.run(\n",
    "                [self.global_step, self.td_err_weight, self.train_op, self.summary_op], feed_dict)\n",
    "            self.writer.add_summary(smr, self.cur_step)\n",
    "        \n",
    "        for ii, td_w in zip(idx, weights):\n",
    "            self.exp_buffer.tree_update(ii, td_w)\n",
    "            \n",
    "        if self.cur_step % self.options['update_steps'] == 0:\n",
    "            print 'Updated target network'\n",
    "            sess.run(self.copy_op)\n",
    "            self.saver.save(sess, self.run_index, global_step=self.global_step)\n",
    "            if self.last_start is not None:\n",
    "                self.writer.add_summary(\n",
    "                    tf.Summary(\n",
    "                        value=[tf.Summary.Value(\n",
    "                                tag='Steps per sec',\n",
    "                                simple_value=self.options['update_steps'] / (time.time() - self.last_start))]),\n",
    "                    self.cur_step)\n",
    "            self.last_start = time.time()\n",
    "\n",
    "    def stat(self, data):\n",
    "        self.writer.add_summary(\n",
    "            tf.Summary(\n",
    "                value=[tf.Summary.Value(tag=name, simple_value=value)\n",
    "                       for name, value in data.items()]), self.cur_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = learner.WeightedExperienceBuffer(0.6, 0.4, 100, buffer_size=1<<18)\n",
    "for _ in range(2):\n",
    "    msg = sock_exp.recv_pyobj()\n",
    "    sock_exp.send('Ok')\n",
    "    if msg['type'] == 'exp':\n",
    "        msg = msg['data']\n",
    "        buf.add(msg['s'], msg['a'], msg['r'], msg['s1'], msg['g'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1420, 262144)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf.inserted, buf.buffer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in xrange(min(buf.buffer_size, buf.inserted)):\n",
    "    buf.tree_update(i, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf.beta = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STATE_STD = STATE_STD.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(device_count = {'GPU': 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ql = QLearner(buf, 2 + 5, run_index='ql-2-fix-norm', options={\n",
    "    'clip_grad': 3.,\n",
    "    'learning_rate': 0.0001,\n",
    "    'update_steps': 20000,\n",
    "})\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in xrange(105):\n",
    "    ql.step(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prioritized replay\n",
    "2. Hanlde death by modifying gamma\n",
    "3. Test Q-learning on simple task\n",
    "4. Combine updates in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/hidden1/weights:0\n",
      "model/hidden1/biases:0\n",
      "model/hidden2/weights:0\n",
      "model/hidden2/biases:0\n",
      "model/value/weights:0\n",
      "model/value/biases:0\n",
      "model/advantage/weights:0\n",
      "model/advantage/biases:0\n",
      "mean:0\n",
      "std:0\n"
     ]
    }
   ],
   "source": [
    "for v in ql.vars_pred:\n",
    "    print v.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FillBuffer(ql, coord):\n",
    "    while not coord.should_stop():\n",
    "        msg = sock_exp.recv_pyobj()\n",
    "        sock_exp.send('Ok')\n",
    "    \n",
    "        if msg['type'] == 'exp':\n",
    "            msg = msg['data']\n",
    "            ql.exp_buffer.add(msg['s'], msg['a'], msg['r'], msg['s1'], msg['g'], 100)\n",
    "        elif msg['type'] == 'stat':\n",
    "            ql.stat(msg['data'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Learn(ql, coord, sess):\n",
    "    i = 0\n",
    "    while not coord.should_stop():\n",
    "        ql.step(sess)\n",
    "        \n",
    "        if i > 0 and i % 500 == 0:\n",
    "            sock_strat.send_pyobj({v.name: sess.run(v, {ql.is_training: False})\n",
    "                                   for v in ql.vars_pred})\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-267-5ce96ff1f744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-207-de5ffb4dd664>\u001b[0m in \u001b[0;36mLearn\u001b[0;34m(ql, coord, sess)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-236-a0dddf58d951>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, sess, batch_size)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtd_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'update_steps'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vertix/dev/aicup/rl/policy/learner.pyc\u001b[0m in \u001b[0;36mtree_update\u001b[0;34m(self, buffer_index, new_weight)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vertix/dev/aicup/rl/policy/learner.pyc\u001b[0m in \u001b[0;36mupdate_up\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_sums\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_min\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Learn(ql, coord, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord = tf.train.Coordinator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threads = [threading.Thread(target=FillBuffer, args=(ql, coord)),\n",
    "           threading.Thread(target=Learn, args=(ql, coord, sess))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threads[0].start()\n",
    "threads[1].start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1823"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.cur_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FillBufferSimple(coord, buf):\n",
    "    while not coord.should_stop():\n",
    "        msg = sock_exp.recv_pyobj()\n",
    "        sock_exp.send('Ok')\n",
    "    \n",
    "        if msg['type'] == 'exp':\n",
    "            msg = msg['data']\n",
    "            buf.add(msg['s'], msg['a'], msg['r'], msg['s1'], msg['g'], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_t = threading.Thread(target=FillBufferSimple, args=(coord, buf))\n",
    "_t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "Use OpenAI env to test Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-23 18:50:09,140] Making new env: LunarLander-v2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buf = WeightedExperienceBuffer()\n",
    "old_s = env.reset()\n",
    "for _ in range(5):\n",
    "    a = env.action_space.sample()\n",
    "    \n",
    "    s, r, d, _ = env.step(a)\n",
    "    buf.add(old_s, a, r, s if not d else None, TD_ERR_CLIP)\n",
    "    old_s = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ql = QLearner(buf, env.action_space.n, 8)\n",
    "# feed_dict = {ql.state: ss, ql.action: aa, ql.reward: rr, ql.state1:ss1, ql.gamma: gg}\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n",
      "Updated target network\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-92fd5629f3e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0md\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTD_ERR_CLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vertix/anaconda2/lib/python2.7/site-packages/gym/core.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vertix/anaconda2/lib/python2.7/site-packages/gym/envs/box2d/lunar_lander.pyc\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApplyLinearImpulse\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mox\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moy\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSIDE_ENGINE_POWER\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms_power\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpulse_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vertix/anaconda2/lib/python2.7/site-packages/gym/envs/box2d/lunar_lander.pyc\u001b[0m in \u001b[0;36mBeginContact\u001b[0;34m(self, contact)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mcontactListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mBeginContact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlander\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcontact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixtureB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "\n",
    "old_s = env.reset()\n",
    "episode_rew = 0.\n",
    "episode_len = 0.\n",
    "\n",
    "for i in range(10000000):\n",
    "    if i % 1 == 0:\n",
    "        epsilon = 1.0 / (1 + (ql.cur_step or 0.) / 1000.)\n",
    "        if np.random.sample() < epsilon:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = sess.run(ql.act_s1, {ql.state1: np.reshape(old_s, (1, -1)),\n",
    "                                     ql.is_training: False})\n",
    "            a = a[0]\n",
    "\n",
    "        s, r, d, _ = env.step(a)\n",
    "        buf.add(old_s, a, r, s if not d else None, TD_ERR_CLIP)\n",
    "        \n",
    "        episode_rew += r\n",
    "        episode_len += 1\n",
    "        \n",
    "        if d:\n",
    "            ql.stat({'Env/Reward': episode_rew, 'Env/Lenght': episode_len})\n",
    "            episode_rew, episode_len = 0., 0.\n",
    "            old_s = env.reset()\n",
    "        else:\n",
    "            old_s = s\n",
    "\n",
    "    ql.step(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1001.0\n"
     ]
    }
   ],
   "source": [
    "old_s = env.reset()\n",
    "done = False\n",
    "r = 0\n",
    "while not done:\n",
    "#     env.render('human')\n",
    "#     print old_s\n",
    "    a = sess.run(ql.act_s1, {ql.state1: np.reshape(old_s, (1, -1)),\n",
    "                             ql.is_training: False})\n",
    "    old_s, reward, done, _ = env.step(a[0])\n",
    "    r += reward\n",
    "    \n",
    "    if r < -1000:\n",
    "        break\n",
    "    \n",
    "print r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_vars = {v.name: v.eval() for v in ql.vars_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'model/advantage/biases:0',\n",
       " u'model/advantage/weights:0',\n",
       " u'model/hidden1/biases:0',\n",
       " u'model/hidden1/weights:0',\n",
       " u'model/hidden2/biases:0',\n",
       " u'model/hidden2/weights:0',\n",
       " u'model/value/biases:0',\n",
       " u'model/value/weights:0']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(network_vars.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Elu(x):\n",
    "    return np.where(x < 0, np.exp(x) - 1, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BatchNorm(state, network_vars, key, shift=True, eps=0.001):\n",
    "    inv = 1.0 / np.sqrt(network_vars[key + '/moving_variance:0'] + eps)\n",
    "\n",
    "    if shift:\n",
    "        return state * inv + (network_vars[key + '/beta:0'] - network_vars[key + '/moving_mean:0'] * inv)\n",
    "    else:\n",
    "        return state * inv + (-network_vars[key + '/moving_mean:0'] * inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QFunction(object):\n",
    "    def __init__(self, network_vars):\n",
    "        self.vars = network_vars\n",
    "\n",
    "    def Q(self, state):\n",
    "#         state = Normalize(state, self.vars['model/mean:0'], self.vars['model/var:0'])\n",
    "        state = BatchNorm(state, self.vars, 'model/norm', shift=False)\n",
    "\n",
    "        state = np.matmul(state, self.vars['model/hidden1/weights:0'])\n",
    "        state += self.vars['model/hidden1/biases:0']\n",
    "        # state = BatchNorm(state, self.vars, 'model/hidden1/BatchNorm')\n",
    "        state = Elu(state)\n",
    "\n",
    "        state = np.matmul(state, self.vars['model/hidden2/weights:0'])\n",
    "        state += self.vars['model/hidden2/biases:0']\n",
    "        # state = BatchNorm(state, self.vars, 'model/hidden2/BatchNorm')\n",
    "        state = Elu(state)\n",
    "\n",
    "        # value = np.matmul(state, self.vars['model/val_hid/weights:0'])\n",
    "        # value += self.vars['model/val_hid/biases:0']\n",
    "        # value = BatchNorm(value, self.vars, 'model/val_hid/BatchNorm')\n",
    "        # value = ReLu(value)\n",
    "        value = np.matmul(state, self.vars['model/value/weights:0'])\n",
    "        value += self.vars['model/value/biases:0']\n",
    "\n",
    "        # adv = np.matmul(state, self.vars['model/adv_hid/weights:0'])\n",
    "        # adv += self.vars['model/adv_hid/biases:0']\n",
    "        # adv = BatchNorm(adv, self.vars, 'model/adv_hid/BatchNorm')\n",
    "        # adv = ReLu(adv)\n",
    "        adv = np.matmul(state, self.vars['model/advantage/weights:0'])\n",
    "        adv += self.vars['model/advantage/biases:0']\n",
    "\n",
    "        return value + (adv - adv.mean(1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, ss, aa, rr, ss1, gg, ww = ql.exp_buffer.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.92744926e-03,  -1.11189019e-02,  -1.30229145e-02,\n",
       "          1.83991902e-03,  -1.30038373e-02,  -7.98689015e-03,\n",
       "         -7.29485415e-04],\n",
       "       [ -9.82989091e-04,  -1.13519998e-02,  -6.05490245e-03,\n",
       "          8.68432131e-03,  -6.10211212e-03,   1.47880614e-03,\n",
       "         -2.00587325e-03],\n",
       "       [ -2.23232387e-03,  -1.66344829e-02,  -1.05185825e-02,\n",
       "          3.23185511e-03,  -8.59550014e-03,  -6.28848234e-03,\n",
       "          1.69825740e-04],\n",
       "       [ -8.51184595e-04,  -1.09778065e-02,  -3.41447210e-03,\n",
       "          1.37389638e-03,  -6.63597416e-03,  -1.76197849e-04,\n",
       "          4.25715977e-03],\n",
       "       [  5.10341488e-06,  -1.06490199e-02,  -2.82861246e-03,\n",
       "          1.96091714e-03,  -5.35972510e-03,  -8.95796227e-04,\n",
       "          1.86092989e-03],\n",
       "       [  1.64952967e-03,  -6.31430326e-03,  -1.34359929e-04,\n",
       "          2.89097405e-03,  -7.24052545e-03,   4.00833832e-03,\n",
       "          1.31299091e-03],\n",
       "       [ -2.26311595e-03,  -1.39367068e-02,  -1.26700234e-02,\n",
       "          4.39036638e-03,  -1.01881921e-02,  -5.02584036e-03,\n",
       "         -3.48311593e-03],\n",
       "       [ -1.84605073e-03,  -1.23067303e-02,  -5.30015491e-03,\n",
       "          6.38269540e-03,  -3.74423643e-03,  -5.58129884e-03,\n",
       "         -1.03529892e-03],\n",
       "       [ -6.60929503e-03,  -7.78199639e-03,  -1.47167854e-02,\n",
       "          4.44569997e-03,  -1.57519542e-02,  -1.02423057e-02,\n",
       "         -1.05576431e-02],\n",
       "       [ -1.93887623e-03,  -1.06352214e-02,  -7.10250624e-03,\n",
       "          1.87499914e-03,  -9.75076854e-03,  -1.02456417e-02,\n",
       "          1.99764874e-03]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.pred_vars[5].eval({ql.state: ss, ql.is_training: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -6.92745066e-03,  -1.11189029e-02,  -1.30229194e-02,\n",
       "          1.83991885e-03,  -1.30038356e-02,  -7.98689320e-03,\n",
       "         -7.29486923e-04],\n",
       "       [ -9.82990431e-04,  -1.13520040e-02,  -6.05490711e-03,\n",
       "          8.68431824e-03,  -6.10211620e-03,   1.47880294e-03,\n",
       "         -2.00587536e-03],\n",
       "       [ -2.23232535e-03,  -1.66344838e-02,  -1.05185814e-02,\n",
       "          3.23185655e-03,  -8.59550059e-03,  -6.28848224e-03,\n",
       "          1.69828431e-04],\n",
       "       [ -8.51183788e-04,  -1.09778067e-02,  -3.41447230e-03,\n",
       "          1.37389636e-03,  -6.63597596e-03,  -1.76202095e-04,\n",
       "          4.25715998e-03],\n",
       "       [  5.10407696e-06,  -1.06490186e-02,  -2.82861120e-03,\n",
       "          1.96091833e-03,  -5.35972460e-03,  -8.95791789e-04,\n",
       "          1.86093314e-03],\n",
       "       [  1.64952601e-03,  -6.31430388e-03,  -1.34360217e-04,\n",
       "          2.89097393e-03,  -7.24052295e-03,   4.00833684e-03,\n",
       "          1.31298873e-03],\n",
       "       [ -2.26311739e-03,  -1.39367085e-02,  -1.26700244e-02,\n",
       "          4.39036150e-03,  -1.01881930e-02,  -5.02584276e-03,\n",
       "         -3.48311420e-03],\n",
       "       [ -1.84604860e-03,  -1.23067306e-02,  -5.30015292e-03,\n",
       "          6.38269272e-03,  -3.74423649e-03,  -5.58129701e-03,\n",
       "         -1.03529539e-03],\n",
       "       [ -6.60929197e-03,  -7.78199953e-03,  -1.47167910e-02,\n",
       "          4.44569980e-03,  -1.57519536e-02,  -1.02423062e-02,\n",
       "         -1.05576437e-02],\n",
       "       [ -1.93887319e-03,  -1.06352187e-02,  -7.10250320e-03,\n",
       "          1.87500115e-03,  -9.75076763e-03,  -1.02456398e-02,\n",
       "          1.99765023e-03]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QFunction(network_vars).Q(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1746.92163086,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,  3156.87939453], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(ql.copy_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Select(ql.pred_vars[2], ql.action).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(ql.pred_vars[2] * tf.one_hot(ql.action, ql.num_actions), reduction_indices=1).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7], dtype=int32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(ql.pred_vars[2]).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.delta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(ql.delta).eval({ql.state: ss, ql.action: aa, ql.reward: rr, ql.state1:ss1, ql.gamma: gg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,  2561.84985352,  2696.66064453,\n",
       "        3319.86474609,  2376.26171875,  2375.80859375,  2602.42016602,\n",
       "        2548.83056641,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval({ql.state: ss, ql.action: aa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268,\n",
       "        9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval({ql.state1: ss1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
