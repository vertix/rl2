{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import zmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_socket_addr = \"tcp://127.0.0.1:19884\" \n",
    "max_actions = 7\n",
    "strat_socket_addr = \"tcp://127.0.0.1:19885\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "sock_exp = context.socket(zmq.REP)\n",
    "sock_exp.bind(exp_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sock_strat = context.socket(zmq.PUB)\n",
    "sock_strat.bind(strat_socket_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.999\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExperienceBuffer(object):\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.ss, self.aa, self.rr, self.ss1, self.gg = None, None, None, None, None\n",
    "        self.buffer_size = buffer_size\n",
    "        self.inserted = 0\n",
    "    \n",
    "    def add(self, s, a, r, s1):\n",
    "        if self.ss is None:\n",
    "            # Initialize\n",
    "            state_size = len(s)\n",
    "            self.ss = np.zeros((state_size, self.buffer_size))\n",
    "            self.aa = np.zeros(self.buffer_size, dtype=np.int16)\n",
    "            self.ss1 = np.zeros((state_size, self.buffer_size))\n",
    "            self.rr = np.zeros(self.buffer_size)\n",
    "            self.gg = np.zeros(self.buffer_size)\n",
    "\n",
    "        cur_index = self.inserted % self.buffer_size\n",
    "        self.ss[:, cur_index] = s\n",
    "        self.aa[cur_index] = a\n",
    "        self.rr[cur_index] = r\n",
    "        if s1 is not None:\n",
    "            self.ss[:, cur_index] = s1\n",
    "            self.gg[cur_index] = GAMMA\n",
    "        else:\n",
    "            self.ss[:, cur_index] = s\n",
    "            self.gg[cur_index] = 0.\n",
    "        \n",
    "        self.inserted += 1\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return None if self.ss is None else self.ss.shape[0]\n",
    "            \n",
    "    def sample(self, size):\n",
    "        if size > self.inserted:\n",
    "            return None, None, None, None, None\n",
    "\n",
    "        indexes = random.sample(range(min(self.inserted, self.buffer_size)), size)\n",
    "\n",
    "        return (np.transpose(self.ss[:,indexes]), self.aa[indexes], self.rr[indexes],\n",
    "                np.transpose(self.ss1[:, indexes]), self.gg[indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateNetwork(state, num_actions, scope, reuse=False):\n",
    "    hidden1 = tf.contrib.layers.relu(\n",
    "        state, 20,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=1.),\n",
    "        biases_initializer=tf.constant_initializer(0.1),\n",
    "        scope=scope + '/hidden1', reuse=reuse)\n",
    "    hidden2 = tf.contrib.layers.relu(\n",
    "        hidden1, 20,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=1.),\n",
    "        biases_initializer=tf.constant_initializer(0.1),\n",
    "        scope=scope + '/hidden2', reuse=reuse)\n",
    "    \n",
    "    value_hid = tf.contrib.layers.relu(hidden2, 20,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=1.),\n",
    "        biases_initializer=tf.constant_initializer(0.1),\n",
    "        scope=scope + '/val_hid', reuse=reuse)\n",
    "\n",
    "    adv_hid = tf.contrib.layers.relu(hidden2, 20,\n",
    "        weights_initializer=tf.truncated_normal_initializer(stddev=1.),\n",
    "        biases_initializer=tf.constant_initializer(0.1),\n",
    "        scope=scope + '/adv_hid', reuse=reuse)\n",
    "\n",
    "    value = tf.contrib.layers.linear(value_hid, 1,\n",
    "                                     scope=scope + '/value', reuse=reuse)\n",
    "    adv = tf.contrib.layers.linear(adv_hid, num_actions, scope=scope + '/advantage', reuse=reuse)\n",
    "    \n",
    "    output = value + (adv - tf.reduce_mean(adv, reduction_indices=1, keep_dims=True))\n",
    "    return hidden1, hidden2, value_hid, adv_hid, value, adv, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Select(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    batch_size = tf.shape(value)[0]\n",
    "    _range = tf.range(0, batch_size)\n",
    "    ind = tf.concat(1, [tf.expand_dims(_range, 1), \n",
    "                        tf.expand_dims(index, 1)])\n",
    "    return tf.gather_nd(value, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Select4(value, index):\n",
    "    # Value - float tensor of (batch, actions) size\n",
    "    # index - int32 tensor of (batch) size\n",
    "    # returns float tensor of batch size where in every batch the element from index is selected\n",
    "    shp = tf.shape(value)\n",
    "    return tf.reduce_sum(value * tf.one_hot(index, shp[1]), reduction_indices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QLearner(object):\n",
    "    def __init__(self, exp_buffer, num_actions, clip_error=5., run_index=1):\n",
    "        self.exp_buffer = exp_buffer\n",
    "        self.num_actions = num_actions\n",
    "        self.run_index = run_index\n",
    "        \n",
    "        self.state = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state')\n",
    "        self.action = tf.placeholder(tf.int32, shape=[None], name='action')\n",
    "        self.reward = tf.placeholder(tf.float32, shape=[None], name='reward')\n",
    "        self.state1 = tf.placeholder(tf.float32, shape=[None, self.exp_buffer.state_size], name='state1')\n",
    "        self.gamma = tf.placeholder(tf.float32, shape=[None], name='gamma')\n",
    "        \n",
    "        self.pred_vars = CreateNetwork(self.state, num_actions, 'model')\n",
    "        self.pred_vars_s1 = CreateNetwork(self.state1, num_actions, 'model', True)                \n",
    "        self.target_vars = CreateNetwork(self.state1, num_actions, 'target')\n",
    "        \n",
    "        self.vars_pred = tf.get_collection(tf.GraphKeys.VARIABLES, 'model')\n",
    "        self.vars_target = tf.get_collection(tf.GraphKeys.VARIABLES, 'target')\n",
    "\n",
    "        self.copy_op = tf.group(\n",
    "            *[tf.assign(y, x) for x, y in zip(self.vars_pred, self.vars_target)]\n",
    "        )\n",
    "\n",
    "        idx = len(self.pred_vars) - 1\n",
    "\n",
    "        self.act_s1 = tf.cast(tf.argmax(self.pred_vars_s1[idx], dimension=1), tf.int32)\n",
    "        self.q_s1 = Select(self.target_vars[idx], self.act_s1)\n",
    "        self.target_q = tf.stop_gradient(self.reward + self.gamma * self.q_s1)\n",
    "        self.q = Select4(self.pred_vars[idx], self.action)\n",
    "\n",
    "        self.delta = tf.clip_by_value(self.target_q - self.q , -clip_error, clip_error)\n",
    "        self.loss = tf.reduce_mean(tf.square(self.delta))\n",
    "\n",
    "        self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        tf.histogram_summary('TD Error', self.delta)\n",
    "        tf.scalar_summary(\"Loss\", tf.clip_by_value(tf.sqrt(self.loss), -10., 100.))\n",
    "        tf.scalar_summary(\"Q Func\", tf.reduce_mean(self.q))\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "        grads = optimizer.compute_gradients(self.loss, self.vars_pred)\n",
    "        if True:\n",
    "            grads = [(tf.clip_by_norm(g, 5.), v) for g, v in grads]\n",
    "               \n",
    "\n",
    "        for grad, v in grads:\n",
    "            tf.histogram_summary(v.name, v)\n",
    "            if grad is not None:\n",
    "                tf.histogram_summary('{}/grad'.format(v.name), grad)\n",
    "\n",
    "        self.train_op = optimizer.apply_gradients(grads, self.global_step)\n",
    "        \n",
    "        self.summary_op = tf.merge_all_summaries()\n",
    "        self.writer = None\n",
    "        self.cur_step = None\n",
    "\n",
    "    def step(self, sess, batch_size=32):\n",
    "        ss, aa, rr, ss1, gg = buf.sample(batch_size)\n",
    "        if ss is None:\n",
    "            return\n",
    "        \n",
    "        if self.writer is None:\n",
    "            self.writer = tf.train.SummaryWriter('/media/vertix/UHDD/tmp/tensorflow_logs/aicup/%d'\n",
    "                                                 % self.run_index)\n",
    "\n",
    "        feed_dict = {self.state: ss, self.action: aa, self.reward: rr, self.state1:ss1,\n",
    "                     self.gamma: gg}\n",
    "\n",
    "        if self.cur_step and self.cur_step % 100 != 0:\n",
    "            self.cur_step, _ = sess.run([self.global_step, self.train_op], feed_dict)\n",
    "        else:\n",
    "            self.cur_step, _, smr = sess.run([self.global_step, self.train_op, self.summary_op], feed_dict)\n",
    "            self.writer.add_summary(smr, self.cur_step)\n",
    "        \n",
    "        if self.cur_step % 10000 == 0:\n",
    "            print 'Updated target network'\n",
    "            sess.run(self.copy_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buf = ExperienceBuffer(5 * 10 ** 6)  # 5 million experiences\n",
    "for _ in range(5):\n",
    "    msg = sock_exp.recv_pyobj()\n",
    "    sock_exp.send('Ok')\n",
    "    buf.add(msg['s'], msg['a'], msg['r'], msg['s1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ql = QLearner(buf, 7, 10000, 1)\n",
    "# feed_dict = {ql.state: ss, ql.action: aa, ql.reward: rr, ql.state1:ss1, ql.gamma: gg}\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(110002):\n",
    "    msg = sock_exp.recv_pyobj()\n",
    "    sock_exp.send('Ok')\n",
    "\n",
    "    buf.add(msg['s'], msg['a'], msg['r'], msg['s1'])\n",
    "    \n",
    "    ql.step(sess)\n",
    "\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        sock_strat.send_pyobj({v.name: sess.run(v)\n",
    "                               for v in ql.vars_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss, aa, rr, ss1, gg = buf.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_vars = {v.name: sess.run(v) for v in ql.vars_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'model/advantage/weights:0',\n",
       " u'model/hidden1/biases:0',\n",
       " u'model/val_hid/weights:0',\n",
       " u'model/val_hid/biases:0',\n",
       " u'model/adv_hid/weights:0',\n",
       " u'model/hidden2/biases:0',\n",
       " u'model/hidden2/weights:0',\n",
       " u'model/hidden1/weights:0',\n",
       " u'model/value/weights:0',\n",
       " u'model/value/biases:0',\n",
       " u'model/adv_hid/biases:0',\n",
       " u'model/advantage/biases:0']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_vars.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.93839359], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_vars['model/value/biases:0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReLu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeQ(state, network_vars):\n",
    "    state = np.matmul(state, network_vars['model/hidden1/weights:0'])\n",
    "    state += network_vars['model/hidden1/biases:0']\n",
    "    state = ReLu(state)\n",
    "    \n",
    "    state = np.matmul(state, network_vars['model/hidden2/weights:0'])\n",
    "    state += network_vars['model/hidden2/biases:0']\n",
    "    state = ReLu(state)\n",
    "       \n",
    "    value = np.matmul(state, network_vars['model/val_hid/weights:0'])\n",
    "    value += network_vars['model/val_hid/biases:0']\n",
    "    value = ReLu(value)\n",
    "    value = np.matmul(value, network_vars['model/value/weights:0'])\n",
    "    value += network_vars['model/value/biases:0']\n",
    "\n",
    "    adv = np.matmul(state, network_vars['model/adv_hid/weights:0'])\n",
    "    adv += network_vars['model/adv_hid/biases:0']\n",
    "    adv = ReLu(adv)\n",
    "    adv = np.matmul(adv, network_vars['model/advantage/weights:0'])\n",
    "    adv += network_vars['model/advantage/biases:0']\n",
    "\n",
    "    return value + (adv - adv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ql.pred_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  23317.3203125 ,  -43890.7734375 ,   83519.8359375 ,\n",
       "          45480.046875  , -159796.640625  ,   30335.5703125 ,\n",
       "         -14911.36230469]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.pred_vars[6].eval({ql.state: ss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  23317.3188833 ,  -43890.77661445,   83519.8318787 ,\n",
       "          45480.04498785, -159796.6405869 ,   30335.57328218,\n",
       "         -14911.36375042]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComputeQ(ss, network_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1746.92163086,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,     0.        ,     0.        ,     0.        ,\n",
       "           0.        ,  3156.87939453], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488,  10.50465488,  10.50465488,\n",
       "        10.50465488,  10.50465488], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(ql.copy_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Select(ql.pred_vars[2], ql.action).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2186.74389648,  6496.70410156,  2797.15771484,  4662.953125  ,\n",
       "           0.        ,  2761.18579102,  3284.98608398,  6556.95996094,\n",
       "        2748.39379883,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(ql.pred_vars[2] * tf.one_hot(ql.action, ql.num_actions), reduction_indices=1).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  7], dtype=int32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(ql.pred_vars[2]).eval(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.,  25.], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.delta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(ql.delta).eval({ql.state: ss, ql.action: aa, ql.reward: rr, ql.state1:ss1, ql.gamma: gg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.        ,     0.        ,  2561.84985352,  2696.66064453,\n",
       "        3319.86474609,  2376.26171875,  2375.80859375,  2602.42016602,\n",
       "        2548.83056641,     0.        ], dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q.eval({ql.state: ss, ql.action: aa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268,\n",
       "        9.87346268,  9.87346268,  9.87346268,  9.87346268,  9.87346268], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ql.q_s1.eval({ql.state1: ss1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
